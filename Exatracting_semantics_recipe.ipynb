{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the spacy and regex implementation for extracting food from recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import library, loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import regex\n",
    "import json\n",
    "# probably other dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./recipe/recipe.json\",\"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "nlp =  spacy.load('en_core_web_lg')\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "from spacy.tokenizer import Tokenizer\n",
    "Tokenizer = Tokenizer(nlp.vocab)\n",
    "Lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "# import en_core_seb_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 1/2 d/d NUM CD\n",
      "cup cup xxx NOUN NN\n",
      "confectioners confectioner xxxx NOUN NNS\n",
      "' ' ' PART POS\n",
      "sugar sugar xxxx NOUN NN\n",
      "for for xxx ADP IN\n",
      "decoration decoration xxxx NOUN NN\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(data[0][\"food_ingredients\"][-1])\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    return nlp(\" \".join(list(map(lambda x: x.lemma_,nlp(text)))))\n",
    "\n",
    "# test= nlp('1 1/4 cups butter')\n",
    "# for token in test:\n",
    "#     if token.tag_ == \"NNS\":\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "#         token = Tokenizer(Lemmatizer(token.text, \"NOUN\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= nlp('1 1/4 cups butter')\n",
    "t = lemmatizer('1 1/4 cups butter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 1/4 cup butter'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    1/2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " cup confectioners' sugar for decoration</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_lg')\n",
    "dog = nlp.vocab[\"dog\"]\n",
    "cat = nlp.vocab[\"cat\"]\n",
    "apple = nlp.vocab[\"apple\"]\n",
    "orange = nlp.vocab[\"orange\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.similarity(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up entity class and entity list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class entity:\n",
    "    def __init__(self, recipe):\n",
    "        self.recipe = recipe\n",
    "        self.ingredient = [x for x in recipe[\"food_ingredients\"]]\n",
    "        self.number = [0.0 for x in recipe[\"food_ingredients\"]]\n",
    "        self.unit = [\"TBD\" for x in recipe[\"food_ingredients\"]]\n",
    "        self.entities = [\"TBD\" for x in recipe[\"food_ingredients\"]]\n",
    "#         self.failure\n",
    "#         self.recipe_triple = []\n",
    "    def get_nlpres(self, nlp_output, index):\n",
    "        if not nlp_output:\n",
    "            self.number[index]=\"TBD\"\n",
    "            self.unit[index] = \"TBD\"\n",
    "            self.entities[index] = \"TBD\"\n",
    "#             print(\"\")\n",
    "            return\n",
    "        res = 0.0\n",
    "        for v in nlp_output:\n",
    "            if v[1] != 'CARDINAL' and v[1] != \"QUANTITY\":\n",
    "#                 print(v)\n",
    "                pass\n",
    "            elif v[1] == \"CARDINAL\":\n",
    "                vals = v[0].split()\n",
    "#                 res = 0.0\n",
    "                for _ in vals:\n",
    "                    try:\n",
    "                        res+=eval(_)\n",
    "                    except:\n",
    "                        break\n",
    "                self.number[index]=res\n",
    "        \n",
    "#                 self.unit.append(\"TBD\")\n",
    "#                 self.entities.append(\"TBD\")\n",
    "            else:\n",
    "                vals = v[0].split()\n",
    "#                 res = 0.0\n",
    "                for _ in vals:\n",
    "                    try:\n",
    "                        res += eval(_)\n",
    "                    except:\n",
    "                        self.unit[index] = _\n",
    "                        break\n",
    "                self.number[index] = res\n",
    "#                 self.entities.append(\"TBD\")\n",
    "            #TBD as default since cannot find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_entity = entity(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = list(map(lambda x:entity(x), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = an_entity.ingredient\n",
    "for i, _ in enumerate(w):\n",
    "    tmp = lemmatizer(_)\n",
    "    an_entity.ingredient[i] = str(tmp)\n",
    "#     print(tmp)\n",
    "    recog = [(d.text, d.label_) for d in tmp.ents]\n",
    "#     print(recog)\n",
    "    an_entity.get_nlpres(recog, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.25, 0.6666666666666666, 1.0, 2.0, 0.125, 0.5, 2.0, 0.5]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an_entity.number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 1/4 cup butter',\n",
       " '2/3 cup white sugar',\n",
       " '1 teaspoon vanilla extract',\n",
       " '2 cup all - purpose flour',\n",
       " '1/8 teaspoon salt',\n",
       " '1/2 cup unsweetened cocoa powder',\n",
       " '2 cup chop pecan',\n",
       " \"1/2 cup confectioner ' sugar for decoration\"]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an_entity.ingredient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run nlp for all_entities and saving as step1 pickle file, in this step, we resolve numbers and unit, item was filled by \"TBD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in all_entities:\n",
    "    words = e.ingredient\n",
    "    for i, w in enumerate(words):\n",
    "        tmp = lemmatizer(w)\n",
    "        e.ingredient[i] = str(tmp)\n",
    "        for t in tmp:\n",
    "            t = t.lemma_\n",
    "        recog = [(d.text, d.label_) for d in tmp.ents]\n",
    "        e.get_nlpres(recog, i)\n",
    "    \n",
    "        # automaticly find\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not have a valid number, discard\n",
    "for _, l in enumerate(all_entities):\n",
    "    for i, n in enumerate(l.number):\n",
    "#         print(i)\n",
    "        if n == \"TBD\":\n",
    "#             print(i)\n",
    "            l.ingredient[i] = \"not valid\"\n",
    "            l.unit[i] = \"not valid\"\n",
    "            l.entities[i] = \"not valid\"\n",
    "            l.number[i] = \"not valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"first_step_number.pkl\", \"wb\") as p:\n",
    "    pickle.dump(all_entities, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload pickled file, start with items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_all_entities = pickle.load(open(\"first_step_number.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.25, 0.6666666666666666, 1.0, 2.0, 0.125, 0.5, 2.0, 0.5]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[0].number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cup',\n",
       " 'cup',\n",
       " 'cup',\n",
       " 'TBD',\n",
       " 'cup',\n",
       " 'TBD',\n",
       " 'TBD',\n",
       " 'teaspoon',\n",
       " 'teaspoon',\n",
       " 'teaspoon',\n",
       " 'teaspoon',\n",
       " 'teaspoon']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[5].unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 1/4 cup butter , soften',\n",
       " '1 1/4 cup white sugar',\n",
       " '3/4 cup light corn syrup',\n",
       " '2 small egg',\n",
       " '3 cup all - purpose flour',\n",
       " '1 1/2 teaspoon baking powder',\n",
       " '1 teaspoon baking soda',\n",
       " '1/2 teaspoon salt',\n",
       " '2 teaspoon ground cinnamon',\n",
       " '2 teaspoon ground clove',\n",
       " '1 teaspoon ground ginger',\n",
       " '1/4 teaspoon ground black pepper']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[5].ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statical result about first step entity recoginition number\n",
    "cnt = 0\n",
    "for l in loaded_all_entities:\n",
    "    for n in l.number:\n",
    "        if n == \"TBD\":\n",
    "            cnt += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "971"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for l in loaded_all_entities:\n",
    "    for n in l.number:\n",
    "        if n == \"not valid\":\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cup', 'cup', 'teaspoon', 'cup', 'teaspoon', 'cup', 'cup', 'TBD']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[0].unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in test:\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9365"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for l in loaded_all_entities:\n",
    "    for n in l.unit:\n",
    "        if n == \"TBD\":\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33456"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for l in loaded_all_entities:\n",
    "    for n in l.unit:\n",
    "        cnt+=1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27991989478718315"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9365/33456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = '3 cup all - purpose flour'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 d NUM CD\n",
      "cup cup xxx NOUN NN\n",
      "all all xxx DET DT\n",
      "- - - PUNCT HYPH\n",
      "purpose purpose xxxx NOUN NN\n",
      "flour flour xxxx NOUN NN\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(test_sentence):\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence2 = \"3 small egg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 d NUM CD\n",
      "small small xxxx ADJ JJ\n",
      "egg egg xxx NOUN NN\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(test_sentence2):\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence3 = \"2 teaspoon ground cinnamon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 d NUM CD\n",
      "teaspoon teaspoon xxxx NOUN NN\n",
      "ground ground xxxx NOUN NN\n",
      "cinnamon cinnamon xxxx NOUN NN\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(test_sentence3):\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence4 = '1 1/4 cup butter , soften'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 d NUM CD\n",
      "1/4 1/4 d/d NUM CD\n",
      "cup cup xxx NOUN NN\n",
      "butter butter xxxx NOUN NN\n",
      ", , , PUNCT ,\n",
      "soften soften xxxx VERB VB\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(test_sentence4):\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only keep NN, remove things already in unit, change \"TBD\" in unit to default unit(\"ge\"), val = \"DEFAULT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in loaded_all_entities:\n",
    "    for i,u in enumerate(l.unit):\n",
    "        if u == \"TBD\":\n",
    "            l.unit[i] = \"DEFAULT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9365"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for l in loaded_all_entities:\n",
    "    for n in l.unit:\n",
    "        if n == \"DEFAULT\":\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in loaded_all_entities:\n",
    "    for i, n in enumerate(l.number):\n",
    "        if l.ingredient[i] != \"not valid\":\n",
    "            tmp = nlp(l.ingredient[i])\n",
    "            res = []\n",
    "            for token in tmp:\n",
    "                if token.tag_ == \",\":\n",
    "                    break\n",
    "                if token.tag_ == \"NN\" or token.tag_ == \"JJ\":\n",
    "                    if token.text != l.unit[i]:\n",
    "                        res.append(token.text)\n",
    "            l.entities[i] = \" \".join(res)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 1/2 d/d NUM CD\n",
      "cup cup xxx NOUN NN\n",
      "confectioners confectioner xxxx NOUN NNS\n",
      "' ' ' PART POS\n",
      "sugar sugar xxxx NOUN NN\n",
      "for for xxx ADP IN\n",
      "decoration decoration xxxx NOUN NN\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(data[0][\"food_ingredients\"][-1])\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['butter',\n",
       " 'white sugar',\n",
       " 'vanilla extract',\n",
       " 'purpose flour',\n",
       " 'salt',\n",
       " 'unsweetened cocoa powder',\n",
       " 'chop pecan',\n",
       " 'cup confectioner sugar decoration']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[0].entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cup', 'cup', 'teaspoon', 'cup', 'teaspoon', 'cup', 'cup', 'DEFAULT']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[0].unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 1/4 cup butter',\n",
       " '2/3 cup white sugar',\n",
       " '1 teaspoon vanilla extract',\n",
       " '2 cup all - purpose flour',\n",
       " '1/8 teaspoon salt',\n",
       " '1/2 cup unsweetened cocoa powder',\n",
       " '2 cup chop pecan',\n",
       " \"1/2 cup confectioner ' sugar for decoration\"]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[0].ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 1/2 d/d NUM CD\n",
      "cup cup xxx NOUN NN\n",
      "unsweetened unsweetened xxxx ADJ JJ\n",
      "cocoa cocoa xxxx NOUN NN\n",
      "powder powder xxxx NOUN NN\n"
     ]
    }
   ],
   "source": [
    "t = '1/2 cup unsweetened cocoa powder'\n",
    "for token in nlp(t):\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for l in loaded_all_entities:\n",
    "    for e in l.entities:\n",
    "        if e == \"TBD\":\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['butter',\n",
       " 'white sugar',\n",
       " 'light corn syrup',\n",
       " 'small egg',\n",
       " 'purpose flour',\n",
       " 'teaspoon baking powder',\n",
       " 'teaspoon baking soda',\n",
       " 'salt',\n",
       " 'ground cinnamon',\n",
       " 'ground clove',\n",
       " 'ground ginger',\n",
       " 'ground black pepper']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[5].entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 1/4 cup butter , soften',\n",
       " '1 1/4 cup white sugar',\n",
       " '3/4 cup light corn syrup',\n",
       " '2 small egg',\n",
       " '3 cup all - purpose flour',\n",
       " '1 1/2 teaspoon baking powder',\n",
       " '1 teaspoon baking soda',\n",
       " '1/2 teaspoon salt',\n",
       " '2 teaspoon ground cinnamon',\n",
       " '2 teaspoon ground clove',\n",
       " '1 teaspoon ground ginger',\n",
       " '1/4 teaspoon ground black pepper']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[5].ingredient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving result to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"extraction.pkl\", \"wb\") as p:\n",
    "    pickle.dump(loaded_all_entities, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving new result to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for l in loaded_all_entities:\n",
    "    output = l.recipe\n",
    "    output[\"extraction_results\"] = []\n",
    "    for i, n in enumerate(l.number):\n",
    "        output[\"extraction_results\"].append((l.number[i], l.unit[i], l.entities[i]))\n",
    "    outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food_url': 'https://www.allrecipes.com/recipe/15253/chocolate-snowballs/',\n",
       " 'type_url': 'https://www.allrecipes.com/recipes/841/holidays-and-events/christmas/desserts/christmas-cookies/',\n",
       " 'type_name': 'Christmas Cookies',\n",
       " 'food_name': 'Chocolate Snowballs',\n",
       " 'food_ingredients': ['1 1/4 cups butter',\n",
       "  '2/3 cup white sugar',\n",
       "  '1 teaspoon vanilla extract',\n",
       "  '2 cups all-purpose flour',\n",
       "  '1/8 teaspoon salt',\n",
       "  '1/2 cup unsweetened cocoa powder',\n",
       "  '2 cups chopped pecans',\n",
       "  \"1/2 cup confectioners' sugar for decoration\"],\n",
       " 'extraction_results': [(1.25, 'cup', 'butter'),\n",
       "  (0.6666666666666666, 'cup', 'white sugar'),\n",
       "  (1.0, 'teaspoon', 'vanilla extract'),\n",
       "  (2.0, 'cup', 'purpose flour'),\n",
       "  (0.125, 'teaspoon', 'salt'),\n",
       "  (0.5, 'cup', 'unsweetened cocoa powder'),\n",
       "  (2.0, 'cup', 'chop pecan'),\n",
       "  (0.5, 'DEFAULT', 'cup confectioner sugar decoration')]}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"recipe_extraction.json\", \"w\") as j:\n",
    "    json.dump(outputs, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Run of NLP, resolving irregular units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import regex\n",
    "import json\n",
    "from collections import Counter\n",
    "nlp =  spacy.load('en_core_web_lg')\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "from spacy.tokenizer import Tokenizer\n",
    "Tokenizer = Tokenizer(nlp.vocab)\n",
    "Lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "def lemmatizer(text):\n",
    "    return nlp(\" \".join(list(map(lambda x: x.lemma_,nlp(text)))))\n",
    "class entity:\n",
    "    def __init__(self, recipe):\n",
    "        self.recipe = recipe\n",
    "        self.ingredient = [x for x in recipe[\"food_ingredients\"]]\n",
    "        self.number = [0.0 for x in recipe[\"food_ingredients\"]]\n",
    "        self.unit = [\"TBD\" for x in recipe[\"food_ingredients\"]]\n",
    "        self.entities = [\"TBD\" for x in recipe[\"food_ingredients\"]]\n",
    "#         self.failure\n",
    "#         self.recipe_triple = []\n",
    "    def get_nlpres(self, nlp_output, index):\n",
    "        if not nlp_output:\n",
    "            self.number[index]=\"TBD\"\n",
    "            self.unit[index] = \"TBD\"\n",
    "            self.entities[index] = \"TBD\"\n",
    "#             print(\"\")\n",
    "            return\n",
    "        res = 0.0\n",
    "        for v in nlp_output:\n",
    "            if v[1] != 'CARDINAL' and v[1] != \"QUANTITY\":\n",
    "#                 print(v)\n",
    "                pass\n",
    "            elif v[1] == \"CARDINAL\":\n",
    "                vals = v[0].split()\n",
    "#                 res = 0.0\n",
    "                for _ in vals:\n",
    "                    try:\n",
    "                        res+=eval(_)\n",
    "                    except:\n",
    "                        break\n",
    "                self.number[index]=res\n",
    "        \n",
    "#                 self.unit.append(\"TBD\")\n",
    "#                 self.entities.append(\"TBD\")\n",
    "            else:\n",
    "                vals = v[0].split()\n",
    "#                 res = 0.0\n",
    "                for _ in vals:\n",
    "                    try:\n",
    "                        res += eval(_)\n",
    "                    except:\n",
    "                        self.unit[index] = _\n",
    "                        break\n",
    "                self.number[index] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./extraction.pkl\", \"rb\") as p:\n",
    "    recipies = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recipies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_set = {\"1/4-inch\", \"4x4-inch\", \"1-inch\", \"1/2-inch\", \"1/8-inch\", \"12-inch\", \"2-inch\", \"degree\", \"f/45\", \"fluid\", \"12x12\", \"half\"}\n",
    "to_default_set = {\"caramel\", \"chicken\", \"cloves\",\"garlic\", \"graham\", \"ice\", \"maraschino\", \"pint\", \"portobello\", \"whole\", \"(\", \"clove\"}\n",
    "removal_set = {\"not valid\", \"red\", \"yellow\", \"toothpick\"}\n",
    "special_treat = {\"skinless\":\"chicken breast halves\"}\n",
    "ounce = {\"ounce\":\"oz\"}\n",
    "DEFAULT = \"DEFAULT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_ingredient = \"1 slice prepared polenta, cut into 4x4-inch piece\"\n",
    "testing_ingredient[35+8+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 slice prepared polenta, cut into piece'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = testing_ingredient.find(\"4x4-inch\")\n",
    "new = testing_ingredient[:pos]+testing_ingredient[pos+len(\"4x4-inch\")+1:]\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 slice prepared polenta, cut into piece'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_word(ingredient, keyword):\n",
    "    pos = ingredient.find(keyword)\n",
    "    return ingredient[:pos]+ingredient[pos+len(keyword)+1:]\n",
    "new = remove_word(testing_ingredient, \"4x4-inch\")\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recipe in recipies:\n",
    "    for index, value in enumerate(recipe.unit): # all has same index\n",
    "        tmp = lemmatizer(recipe.ingredient[index]) # lemmatize\n",
    "        recipe.ingredient[index] = str(tmp)\n",
    "        if value in removal_set: # SET TO NOT VALID\n",
    "            recipe.unit[index] = \"not valid\"\n",
    "            recipe.entities[index] = \"not valid\"\n",
    "            recipe.number[index] = \"not valid\"\n",
    "            recipe.ingredient[index] = \"not valid\"\n",
    "        elif value in to_default_set: # change to DEFAULT ON VALUE\n",
    "            recipe.unit[index] = DEFAULT\n",
    "            \n",
    "        elif value in special_treat or recipe.entities[index] in special_treat:\n",
    "            recipe.unit[index] = DEFAULT\n",
    "            recipe.entities[index] = special_treat[\"skinless\"]\n",
    "        \n",
    "        elif value in ounce:\n",
    "            recipe.unit[index] = ounce[value]\n",
    "        \n",
    "        elif value in nlp_set:\n",
    "            to_be_remove = recipe.ingredient[index]\n",
    "            recipe.ingredient[index] = remove_word(to_be_remove, value)\n",
    "            tmp = nlp(recipe.ingredient[index])\n",
    "            recog = [(d.text, d.label_) for d in tmp.ents] #recog again, reset unit\n",
    "            for v in recog:\n",
    "                if v[1] == \"QUANTITY\":        \n",
    "                    vals = v[0].split()\n",
    "                    res = 0.0\n",
    "                    for _ in vals:\n",
    "                        try:\n",
    "                            res += eval(_)\n",
    "                        except:\n",
    "                            if _ == \"ounce\":\n",
    "                                recipe.unit[index] = ounce[_]\n",
    "                            else:\n",
    "                                recipe.unit[index] = _\n",
    "                            break\n",
    "                else:\n",
    "                    recipe.unit[index] = DEFAULT\n",
    "            res = []\n",
    "            for token in tmp:\n",
    "                if token.tag_ == \",\":\n",
    "                    break\n",
    "                if token.tag_ == \"NN\" or token.tag_ == \"JJ\":\n",
    "                    if token.text != recipe.unit[index]:\n",
    "                        res.append(token.text)\n",
    "            recipe.entities[index] = \" \".join(res)  \n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recipies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "all_units = reduce(lambda x,y:x.union(y) ,(map(lambda x: set(x.unit), recipies)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1/4-inch',\n",
       " 'DEFAULT',\n",
       " 'clove',\n",
       " 'cube',\n",
       " 'cup',\n",
       " 'degree',\n",
       " 'fluid',\n",
       " 'gallon',\n",
       " 'gram',\n",
       " 'inch',\n",
       " 'liter',\n",
       " 'milliliter',\n",
       " 'not valid',\n",
       " 'oz',\n",
       " 'pound',\n",
       " 'quart',\n",
       " 'skinless',\n",
       " 'tablespoon',\n",
       " 'teaspoon',\n",
       " 'toothpick'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./second_round_extraction.pkl\"\n",
    "with open(file, \"wb\") as w:\n",
    "    pickle.dump(recipies, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save load scond round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file,\"rb\") as f:\n",
    "    new_recipies = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_units = reduce(lambda x,y:x.union(y) ,(map(lambda x: set(x.unit), recipies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1/4-inch',\n",
       " 'DEFAULT',\n",
       " 'clove',\n",
       " 'cube',\n",
       " 'cup',\n",
       " 'degree',\n",
       " 'fluid',\n",
       " 'gallon',\n",
       " 'gram',\n",
       " 'inch',\n",
       " 'liter',\n",
       " 'milliliter',\n",
       " 'not valid',\n",
       " 'oz',\n",
       " 'pound',\n",
       " 'quart',\n",
       " 'skinless',\n",
       " 'tablespoon',\n",
       " 'teaspoon',\n",
       " 'toothpick'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "for j, r in enumerate(recipies):\n",
    "    for i, v in enumerate(r.unit):\n",
    "        if 'skinless' in v:\n",
    "            q.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3567]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-f743eed9f778>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecipies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "recipies[q[1]].unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 cup coconut milk',\n",
       " '1 cup pineapple juice',\n",
       " '1/2 cup rum',\n",
       " '4 tablespoon white sugar',\n",
       " '8 cube ice']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipies[q[1]].ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food_url': 'https://www.allrecipes.com/recipe/32632/pina-colada-iii/',\n",
       " 'type_url': 'https://www.allrecipes.com/recipes/133/drinks/cocktails/',\n",
       " 'type_name': 'Cocktail Recipes',\n",
       " 'food_name': 'Pina Colada III',\n",
       " 'food_ingredients': ['1 cup coconut milk',\n",
       "  '1 cup pineapple juice',\n",
       "  '1/2 cup rum',\n",
       "  '4 tablespoons white sugar',\n",
       "  '8 cubes ice']}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipies[q[1]].recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nlp(\"1 ( 14 ounce ) package deluxe macaroni and cheese dinner mix ( such as kraft Â® )\")\n",
    "recog = [(d.text, d.label_) for d in t.ents]\n",
    "rotk = []\n",
    "for v in recog:\n",
    "    if v[1] == \"QUANTITY\":        \n",
    "        vals = v[0].split()\n",
    "#                 res = 0.0\n",
    "        for _ in vals:\n",
    "            res = 0.0\n",
    "            try:\n",
    "                res += eval(_)\n",
    "            except:\n",
    "                rotk.append(_)\n",
    "                \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1/2 cup warm water ( 110 degree c )'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_word('1/2 cup warm water ( 110 degree degree c )', \"degree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 bunch slender asparagus spear , trim , cut on diagonal into piece'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_word('1 bunch slender asparagus spear , trim , cut on diagonal into 1-inch piece', \"1-inch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_set = {\"1/4-inch\", \"4x4-inch\", \"1-inch\", \"1/2-inch\", \"1/8-inch\", \"12-inch\", \"2-inch\", \"degree\", \"f/45\", \"fluid\", \"12x12\", \"half\", \"degree degree\"}\n",
    "to_default_set = {\"caramel\", \"chicken\", \"cloves\",\"garlic\", \"graham\", \"ice\", \"maraschino\", \"pint\", \"portobello\", \"whole\", \"(\", \"clove\"}\n",
    "removal_set = {\"not valid\", \"red\", \"yellow\", \"toothpick\"}\n",
    "special_treat = {\"skinless\":\"chicken breast halves\"}\n",
    "ounce = {\"ounce\":\"oz\"}\n",
    "DEFAULT = \"DEFAULT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recipe in new_recipies:\n",
    "    for index, value in enumerate(recipe.unit): # all has same index\n",
    "        tmp = lemmatizer(recipe.ingredient[index]) # lemmatize\n",
    "        recipe.ingredient[index] = str(tmp)\n",
    "        if value in removal_set: # SET TO NOT VALID\n",
    "            recipe.unit[index] = \"not valid\"\n",
    "            recipe.entities[index] = \"not valid\"\n",
    "            recipe.number[index] = \"not valid\"\n",
    "            recipe.ingredient[index] = \"not valid\"\n",
    "        elif value in to_default_set: # change to DEFAULT ON VALUE\n",
    "            recipe.unit[index] = DEFAULT\n",
    "            \n",
    "        elif value in special_treat or recipe.entities[index] in special_treat:\n",
    "            recipe.unit[index] = DEFAULT\n",
    "            recipe.entities[index] = special_treat[\"skinless\"]\n",
    "        \n",
    "        elif value in ounce:\n",
    "            recipe.unit[index] = ounce[value]\n",
    "        \n",
    "        elif value in nlp_set:\n",
    "            to_be_remove = recipe.ingredient[index]\n",
    "            recipe.ingredient[index] = remove_word(to_be_remove, value)\n",
    "            tmp = nlp(recipe.ingredient[index])\n",
    "            recog = [(d.text, d.label_) for d in tmp.ents] #recog again, reset unit\n",
    "            for v in recog:\n",
    "                if v[1] == \"QUANTITY\":        \n",
    "                    vals = v[0].split()\n",
    "                    res = 0.0\n",
    "                    for _ in vals:\n",
    "                        try:\n",
    "                            res += eval(_)\n",
    "                        except:\n",
    "                            if _ == \"ounce\":\n",
    "                                recipe.unit[index] = ounce[_]\n",
    "                            else:\n",
    "                                recipe.unit[index] = _\n",
    "                            break\n",
    "                else:\n",
    "                    recipe.unit[index] = DEFAULT\n",
    "            res = []\n",
    "            for token in tmp:\n",
    "                if token.tag_ == \",\":\n",
    "                    break\n",
    "                if token.tag_ == \"NN\" or token.tag_ == \"JJ\":\n",
    "                    if token.text != recipe.unit[index]:\n",
    "                        res.append(token.text)\n",
    "            recipe.entities[index] = \" \".join(res)  \n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_recipies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_units = reduce(lambda x,y:x.union(y) ,(map(lambda x: set(x.unit), new_recipies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DEFAULT',\n",
       " 'cube',\n",
       " 'cup',\n",
       " 'gallon',\n",
       " 'gram',\n",
       " 'inch',\n",
       " 'liter',\n",
       " 'milliliter',\n",
       " 'not valid',\n",
       " 'oz',\n",
       " 'pound',\n",
       " 'quart',\n",
       " 'tablespoon',\n",
       " 'teaspoon'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "for j, r in enumerate(new_recipies):\n",
    "    for i, v in enumerate(r.unit):\n",
    "        if 'degree' in v:\n",
    "            q.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 times iterations of NLP, we removed all no good units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./third_round_extraction.pkl\"\n",
    "with open(file, \"wb\") as w:\n",
    "    pickle.dump(new_recipies, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = []\n",
    "# for l in loaded_all_entities:\n",
    "#     output = l.recipe\n",
    "#     output[\"extraction_results\"] = []\n",
    "#     for i, n in enumerate(l.number):\n",
    "#         output[\"extraction_results\"].append((l.number[i], l.unit[i], l.entities[i]))\n",
    "#     outputs.append(output)\n",
    "outputs = []\n",
    "for l in new_recipies:\n",
    "    output = l.recipe\n",
    "    output[\"extraction_results\"] = []\n",
    "    for i, n in enumerate(l.number):\n",
    "        output[\"extraction_results\"].append((l.number[i], l.unit[i], l.entities[i]))\n",
    "    outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food_url': 'https://www.allrecipes.com/recipe/15253/chocolate-snowballs/',\n",
       " 'type_url': 'https://www.allrecipes.com/recipes/841/holidays-and-events/christmas/desserts/christmas-cookies/',\n",
       " 'type_name': 'Christmas Cookies',\n",
       " 'food_name': 'Chocolate Snowballs',\n",
       " 'food_ingredients': ['1 1/4 cups butter',\n",
       "  '2/3 cup white sugar',\n",
       "  '1 teaspoon vanilla extract',\n",
       "  '2 cups all-purpose flour',\n",
       "  '1/8 teaspoon salt',\n",
       "  '1/2 cup unsweetened cocoa powder',\n",
       "  '2 cups chopped pecans',\n",
       "  \"1/2 cup confectioners' sugar for decoration\"],\n",
       " 'extraction_results': [(1.25, 'cup', 'butter'),\n",
       "  (0.6666666666666666, 'cup', 'white sugar'),\n",
       "  (1.0, 'teaspoon', 'vanilla extract'),\n",
       "  (2.0, 'cup', 'purpose flour'),\n",
       "  (0.125, 'teaspoon', 'salt'),\n",
       "  (0.5, 'cup', 'unsweetened cocoa powder'),\n",
       "  (2.0, 'cup', 'chop pecan'),\n",
       "  (0.5, 'DEFAULT', 'cup confectioner sugar decoration')]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"recipe_extraction.json\", \"w\") as j:\n",
    "    json.dump(outputs, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3]",
   "language": "python",
   "name": "conda-env-miniconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
